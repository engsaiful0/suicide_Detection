# -*- coding: utf-8 -*-
"""T2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQLRZwLkzxXJmovNYiaKtFfG_P1pEDNs
"""

# @title Install Required Libraries
!pip install imbalanced-learn xgboost lightgbm shap tensorflow

# @title Import Libraries
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt

# NLP & ML
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Imbalance handling
from imblearn.over_sampling import BorderlineSMOTE

# Models
from sklearn.naive_bayes import MultinomialNB
from xgboost import XGBClassifier
import lightgbm as lgb

# Explainable AI
import shap

# @title Load Dataset
from google.colab import files
files.upload()
file_path = "suicidal_ideation_reddit_annotated.csv"
df = pd.read_csv(file_path)
df.head()

# @title le = LabelEncoder()
from sklearn.preprocessing import LabelEncoder

# create LabelEncoder instance
le = LabelEncoder()

# encode the labels
df['label'] = le.fit_transform(df['label'])

# separate features and target
X = df['usertext']
y = df['label']

# @title TF-IDF Feature Extraction

# Drop rows where text is NaN
df.dropna(subset=['usertext'], inplace=True)

X = df['usertext']
y = df['label']

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(
    max_features=5000,
    stop_words='english'
)

X_tfidf = tfidf.fit_transform(X)

# @title Train–Test Split
# Keep only required columns
df = df[['usertext', 'label']]

# Remove rows with missing text or label
df.dropna(subset=['usertext', 'label'], inplace=True)

# Reset index (VERY important)
df.reset_index(drop=True, inplace=True)

print(df.shape)  # sanity check


from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y = le.fit_transform(df['label'])

from sklearn.feature_extraction.text import TfidfVectorizer

# Enhanced TF-IDF with more features and n-grams
tfidf = TfidfVectorizer(
    max_features=10000,  # Increased from 5000
    stop_words='english',
    ngram_range=(1, 3),  # Add unigrams, bigrams, and trigrams
    min_df=2,  # Minimum document frequency
    max_df=0.95,  # Maximum document frequency
    sublinear_tf=True  # Apply sublinear tf scaling
)

X_tfidf = tfidf.fit_transform(df['usertext'])

print(X_tfidf.shape[0], len(y))

# @title Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_tfidf, y, test_size=0.2, random_state=42, stratify=y
)

# @title Handle Data Imbalance — Borderline-SMOTE
smote = BorderlineSMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# @title Feature Selection for Better Accuracy
from sklearn.feature_selection import SelectKBest, chi2

# Select top features using chi2 (works well with TF-IDF)
original_features = X_train_res.shape[1]
k_best = min(8000, original_features)  # Select top 8000 features or all if less
selector = SelectKBest(chi2, k=k_best)
X_train_res = selector.fit_transform(X_train_res, y_train_res)
X_test = selector.transform(X_test)

print(f"Selected {k_best} best features out of {original_features}")

accuracy_dict = {}

# @title Model 1 — Multinomial Naïve Bayes
nb = MultinomialNB()
nb.fit(X_train_res, y_train_res)

y_pred_nb = nb.predict(X_test)

accuracy_dict['Naive Bayes'] = accuracy_score(y_test, y_pred_nb)

print("Naive Bayes Accuracy:", accuracy_dict['Naive Bayes'])
print(classification_report(y_test, y_pred_nb))

#@title Model 2 — XGBoost
xgb = XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric='logloss',
    random_state=42
)

xgb.fit(X_train_res, y_train_res)

y_pred_xgb = xgb.predict(X_test)

accuracy_dict['XGBoost'] = accuracy_score(y_test, y_pred_xgb)

print("XGBoost Accuracy:", accuracy_dict['XGBoost'])
print(classification_report(y_test, y_pred_xgb))

#@title Model 3 — LightGBM (Optimized for 94%+ Accuracy)
# Create validation set for early stopping
from scipy.sparse import vstack
from sklearn.model_selection import train_test_split

X_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(
    X_train_res, y_train_res, test_size=0.15, random_state=42, stratify=y_train_res
)

# Optimized LightGBM with hyperparameter tuning for 94%+ accuracy
lgbm = lgb.LGBMClassifier(
    n_estimators=3000,  # More estimators for better learning
    learning_rate=0.005,  # Very low learning rate for fine-tuning
    max_depth=12,  # Deeper trees to capture complex patterns
    num_leaves=50,  # More leaves for better granularity
    min_child_samples=15,  # Lower threshold for more splits
    min_split_gain=0.0,  # Allow more splits
    subsample=0.85,  # Row sampling
    colsample_bytree=0.85,  # Feature sampling
    colsample_bynode=0.85,  # Per-node feature sampling
    reg_alpha=0.05,  # L1 regularization (reduced for more complexity)
    reg_lambda=0.05,  # L2 regularization (reduced for more complexity)
    boosting_type='gbdt',
    objective='binary',
    metric='binary_logloss',
    is_unbalance=False,  # We're using SMOTE, so balance is handled
    random_state=42,
    n_jobs=-1,  # Use all cores
    verbose=-1,  # Suppress output
    force_row_wise=True  # Remove overhead warning
)

# Train with early stopping and best iteration
lgbm.fit(
    X_train_lgb, y_train_lgb,
    eval_set=[(X_val_lgb, y_val_lgb)],
    callbacks=[
        lgb.early_stopping(stopping_rounds=200, verbose=False),  # More patience
        lgb.log_evaluation(period=0)  # Suppress evaluation logs
    ]
)

print(f"Best iteration: {lgbm.best_iteration_}")

y_pred_lgbm = lgbm.predict(X_test)

accuracy_dict['LightGBM'] = accuracy_score(y_test, y_pred_lgbm)

print("LightGBM Accuracy:", accuracy_dict['LightGBM'])
print(classification_report(y_test, y_pred_lgbm))

# @title ACCURACY COMPARISON TABLE (Paper-Ready)
accuracy_df = pd.DataFrame.from_dict(
    accuracy_dict, orient='index', columns=['Accuracy']
)

accuracy_df

#@title SHAP for XGBoost

import shap

# Dense conversion (limited samples)
X_test_dense = X_test.toarray()[:200]

# NEW API: call explainer directly
explainer = shap.TreeExplainer(xgb)
shap_exp = explainer(X_test_dense)

# Bar plot (global importance)
shap.plots.bar(shap_exp)

# @title SHAP for LightGBM
import shap
import numpy as np

# Convert sparse matrices to dense (LIMITED samples)
X_train_dense = X_train_res.toarray()
X_test_dense = X_test.toarray()

# Ensure numeric dtype (very important!)
X_train_dense = X_train_dense.astype(np.float32)
X_test_dense = X_test_dense.astype(np.float32)

# Use TreeExplainer explicitly
explainer_lgbm = shap.TreeExplainer(lgbm)

# Compute SHAP values (small subset)
shap_values_lgbm = explainer_lgbm.shap_values(X_test_dense[:200])

# Plot global importance
shap.summary_plot(
    shap_values_lgbm,
    X_test_dense[:200],
    feature_names=tfidf.get_feature_names_out()
)

# @ tittle IMPORT REQUIRED METRICS
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, auc

# @ tittle CONFUSION MATRIX (CF Matrix)
def plot_all_confusion_matrices(y_test, predictions, model_names):
    fig, axes = plt.subplots(1, len(predictions), figsize=(18, 4))

    for ax, y_pred, name in zip(axes, predictions, model_names):
        cm = confusion_matrix(y_test, y_pred)
        ax.imshow(cm)
        ax.set_title(name)
        ax.set_xlabel("Predicted")
        ax.set_ylabel("Actual")

        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ax.text(j, i, cm[i, j], ha="center", va="center")

    plt.suptitle("Confusion Matrices for All Models", fontsize=14)
    plt.tight_layout()
    plt.show()

predictions = [
    y_pred_nb,
    y_pred_xgb,
    y_pred_lgbm
]

model_names = [
    "Naive Bayes",
    "XGBoost",
    "LightGBM"
]

plot_all_confusion_matrices(y_test, predictions, model_names)

#  @ title ROC CURVE

# Convert to dense for Naive Bayes
X_train_nb = X_train_res.toarray() if hasattr(X_train_res, "toarray") else X_train_res
X_test_nb = X_test.toarray() if hasattr(X_test, "toarray") else X_test

# --- Train GaussianNB ---
from sklearn.naive_bayes import GaussianNB
nb_model = GaussianNB()
nb_model.fit(X_train_nb, y_train_res)

# --- Train XGBoost ---
import xgboost as xgb
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train_res, y_train_res)

# --- Train LightGBM ---
import lightgbm as lgb
lgbm_model = lgb.LGBMClassifier()
lgbm_model.fit(X_train_res, y_train_res)

# ===========================
#  Predict Probabilities
# ===========================
y_prob_nb = nb_model.predict_proba(X_test_nb)[:, 1]  # dense required
y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]   # sparse/dense ok
y_prob_lgbm = lgbm_model.predict_proba(X_test)[:, 1] # sparse/dense ok

# ===========================
# ROC Curve
# ===========================
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

probabilities = {
    "Naive Bayes": y_prob_nb,
    "XGBoost": y_prob_xgb,
    "LightGBM": y_prob_lgbm
}

plt.figure(figsize=(8,6))
for name, probs in probabilities.items():
    fpr, tpr, _ = roc_curve(y_test, probs)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

plt.plot([0,1], [0,1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.show()

#@title Suicide Method Detection Model (Phase 2)
# Step 1: Import Libraries
import pandas as pd
import numpy as np
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# Step 2: Load Dataset
from google.colab import files
files.upload()
file_path = "suicidal_ideation_reddit_annotated.csv"
df = pd.read_csv(file_path)
df.head()

# Step 4: Clean Text
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+", "", text)
    text = text.translate(str.maketrans("", "", string.punctuation))
    text = re.sub(r"\d+", "", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

df["clean_text"] = df["usertext"].apply(clean_text)

# Suicide method keywords
suicide_methods = {
    "hanging": ["hang", "rope", "neck", "ceiling", "fan"],
    "jumping": ["jump", "bridge", "roof", "building", "cliff"],
    "poison": ["poison", "acid", "toxic", "pills", "drink"],
    "overdose": ["overdose", "sleeping pills", "too many pills", "medicine"],
    "drowning": ["drown", "water", "river", "lake", "sea"],
    "shooting": ["shoot", "gun", "bullet", "pistol"],
    "cutting": ["cut", "knife", "wrist", "bleed", "razor"],
    "car_crash": ["crash", "drive", "car", "accident", "road"]
}

# Function to detect method
def detect_method(text):
    for method, keywords in suicide_methods.items():
        for word in keywords:
            if word in text:
                return method
    return "unknown"

# Apply only to suicidal posts
df["predicted_method"] = df.apply(lambda row: detect_method(row["clean_text"]) if row["label"] == 1 else "not_suicidal", axis=1)

# Save or preview
print(df[["usertext", "label", "predicted_method"]].head(20))

# Summary of detected methods
method_counts = df["predicted_method"].value_counts()
print("\nDetected Method Counts:\n", method_counts)



# Step 5: Plot Suicide Method Distribution

plt.figure(figsize=(10, 6))
method_counts.plot(kind="bar")

plt.title("Distribution of Detected Suicide Methods", fontsize=14)
plt.xlabel("Suicide Method", fontsize=12)
plt.ylabel("Number of Posts", fontsize=12)
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.6)

plt.tight_layout()
plt.show()

